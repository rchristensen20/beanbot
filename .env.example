# Discord Bot
DISCORD_TOKEN=your-discord-bot-token
REMINDERS_CHANNEL_ID=0
JOURNAL_CHANNEL_ID=0
QUESTIONS_CHANNEL_ID=0
KNOWLEDGE_INGEST_CHANNEL_ID=0

# Google Gemini API (get your key at https://aistudio.google.com/apikey)
GOOGLE_API_KEY=your-gemini-api-key
GEMINI_MODEL=gemini-2.5-flash

# OpenWeatherMap (get your key at https://openweathermap.org/api)
OPENWEATHER_API_KEY=your-openweather-api-key
WEATHER_LAT=40.0150
WEATHER_LON=-105.2705

# Timezone (IANA format — see https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)
BOT_TIMEZONE=America/Denver

# --- LLM Settings ---
# LLM timeout in seconds
LLM_TIMEOUT=60
# LLM temperature (0 = deterministic, higher = more creative)
LLM_TEMPERATURE=0
# Max conversation turns kept in context window
MAX_CONTEXT_TURNS=10

# --- Weather ---
# Units: "metric" (°C, mm) or "imperial" (°F, in)
WEATHER_UNITS=metric
# Frost alert thresholds
FROST_THRESHOLD_C=2
FROST_THRESHOLD_F=36
# Rain alert thresholds (probability %, precipitation amount in mm)
RAIN_PROB_THRESHOLD_PCT=60
RAIN_MM_THRESHOLD=10
# Forecast entries to fetch (16 x 3hr = 48 hours)
FORECAST_ENTRY_COUNT=16

# --- Schedule (24h HH:MM format) ---
# Morning briefing time
BRIEFING_TIME=08:00
# Evening debrief time
DEBRIEF_TIME=20:00
# Weekly recap time + day (0=Monday, 6=Sunday)
WEEKLY_RECAP_TIME=20:00
WEEKLY_RECAP_DAY=6
# Weather alert check interval in hours
WEATHER_ALERT_INTERVAL_HOURS=6
# Database pruning time
DB_PRUNE_TIME=03:00

# --- Retention ---
# Days to keep ephemeral conversation threads
DB_PRUNE_RETENTION_DAYS=7
# Max checkpoints to keep per persistent thread
DB_PRUNE_MAX_CHECKPOINTS=20

# --- Ingestion & Limits ---
# Max characters per ingestion chunk
INGESTION_CHUNK_SIZE=50000
# HTTP timeout (seconds) when fetching URLs for ingestion
URL_FETCH_TIMEOUT=30
# Max URLs to fetch per single ingest message
MAX_INGEST_URLS=5
# Max days allowed for !recap command
MAX_RECAP_DAYS=90
# Max same-domain links to crawl from a fetched page
MAX_CRAWL_LINKS=50
# Concurrent URL fetches during crawl
CRAWL_CONCURRENCY=5

# --- Categorization (!consolidate) ---
# Files per LLM batch during categorization
CATEGORIZE_BATCH_SIZE=200
# Max output tokens for categorization LLM calls
CATEGORIZE_MAX_TOKENS=16384
